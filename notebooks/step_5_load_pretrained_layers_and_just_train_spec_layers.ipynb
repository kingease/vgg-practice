{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "sys.path.append('../datasets/')\n",
    "sys.path.append('../nets/')\n",
    "sys.path.append('../preprocessing/')\n",
    "\n",
    "import orientset\n",
    "oriset = orientset.get_split('', '../data/tfrecord/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ori_network(inputs, is_training=True, keep_prob=0.5, scope='ori_network'):\n",
    "    with tf.variable_scope(scope, 'ori_network', [inputs]) as sc:\n",
    "        with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                        weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "            net = slim.conv2d(net, 1024, [7, 7], padding='VALID', scope='fc6')\n",
    "            net = slim.dropout(net, keep_prob, is_training=is_training,\n",
    "                         scope='dropout6')\n",
    "            # fully-connected network\n",
    "            net = slim.fully_connected(net, 512, scope='fc7')\n",
    "            net = slim.dropout(net, keep_prob, is_training=is_training, scope='dropout7')\n",
    "            # output layer which has four classes\n",
    "            net = slim.fully_connected(net, 4, scope='fc8', activation_fn=None)\n",
    "            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "            return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restore and trainable spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import vgg_preprocessing, vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../checkpoints/vgg_16.ckpt\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global_step/sec: 0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    # read train data\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(oriset)\n",
    "    image, label = data_provider.get(['image', 'label'])\n",
    "    VGG_IMAGE_SIZE = vgg.vgg_16.default_image_size\n",
    "    image = vgg_preprocessing.preprocess_for_train(image, VGG_IMAGE_SIZE, VGG_IMAGE_SIZE)\n",
    "    \n",
    "    # batch data\n",
    "    batch_image, batch_label = tf.train.batch([image, label], batch_size=32, allow_smaller_final_batch=True)\n",
    "    batch_one_hot_label = slim.one_hot_encoding(batch_label, oriset.num_classes)\n",
    "    batch_one_hot_label = tf.squeeze(batch_one_hot_label, [1])\n",
    "    \n",
    "    # create the training net\n",
    "    logits = ori_network(batch_image, is_training=True)\n",
    "\n",
    "    # create loss\n",
    "    total_loss = tf.losses.softmax_cross_entropy(batch_one_hot_label, logits)\n",
    "    tf.summary.scalar('total_loss', total_loss)\n",
    "    \n",
    "    # find the variablee we want to train\n",
    "    scopes =['ori_network/fc6', 'ori_network/fc7', 'ori_network/fc8']\n",
    "    variables_to_train =[]\n",
    "    for scope in scopes:\n",
    "        variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)\n",
    "        variables_to_train.extend(variables)\n",
    "    \n",
    "    # restore the specified layers' parameters\n",
    "    variables_to_restore = slim.get_variables_to_restore(exclude=scopes)\n",
    "    variables_to_restore = { var.op.name.replace('ori_network', 'vgg_16'):var for var in variables_to_restore}\n",
    "    \n",
    "    # create optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.00001)\n",
    "\n",
    "    # create train_op\n",
    "    train_op = slim.learning.create_train_op(total_loss, \n",
    "                                             optimizer, \n",
    "                                             variables_to_train=variables_to_train,\n",
    "                                             summarize_gradients=True)\n",
    "    \n",
    "    # restore parameters\n",
    "    init_fn = slim.assign_from_checkpoint_fn('../checkpoints/vgg_16.ckpt',variables_to_restore)\n",
    "    \n",
    "    # start to learn\n",
    "    slim.learning.train(train_op, './logs/', log_every_n_steps=1, \n",
    "                        init_fn=init_fn, \n",
    "                        save_summaries_secs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:digitrecon]",
   "language": "python",
   "name": "conda-env-digitrecon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
